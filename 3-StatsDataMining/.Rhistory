orig_telco$churn <- ifelse(orig_telco$churn=='No', 0, 1)
#orig_telco$churn=as.factor(orig_telco$churn)
orig_telco %<>% mutate(across(where(is.character),as_factor))
str(orig_telco)
cor(orig_telco$tenure,orig_telco$churn)
telco_phone <- subset(orig_telco,phoneservice=="Yes" & internetservice=="No")
#Validate the split of data
unique(telco_phone$phoneservice)
unique(telco_phone$internetservice)
#Clean up the data by making monthlycharges categorical data instead of continuous data
telco_phone <- telco_phone %>%
mutate(mthlychrgcat = if_else(monthlycharges< median(telco_phone$monthlycharges), "Less than Median", "More than Median"))
telco_phone = subset(telco_phone, select = -c(internetservice,onlinesecurity,onlinebackup,deviceprotection,techsupport,streamingtv,streamingmovies,monthlycharges) )
#Check for NA rows and remove if small number of rows are affected
names(which(colSums(is.na(telco_phone))>0))
telco_phone<-telco_phone[!(is.na(telco_phone[["totalcharges"]])),]
names(which(colSums(is.na(telco_phone))>0))
#Calculate the percentage of customers who churn
sum(telco_phone$churn == "1")/nrow(telco_phone)*100
str(telco_phone)
cor(telco_phone$tenure,telco_phone$churn)
phoneglm1 <- glm(churn ~ tenure + multiplelines + contract + mthlychrgcat, family=binomial (link="logit"),data=telco_phone)
summary(phoneglm1)
# AIC = 643.4
phoneglm2 <- glm(churn ~ partner + dependents + tenure + contract, family=binomial (link="logit"),data=telco_phone)
summary(phoneglm2)
# AIC = 642.46
phoneglm3 <- glm(churn ~ tenure + contract, family=binomial (link="logit"),data=telco_phone)
summary(phoneglm3)
# AIC = 639.66
phoneglm4 <- glm(churn ~ tenure + contract, family=binomial (link="probit"),data=telco_phone)
summary(phoneglm4)
# AIC = 644.3
stargazer(phoneglm1, phoneglm2, phoneglm3, phoneglm4, title="Logit/Probit Phone Only - Customer Churn Comparison", type="text")
set.seed(6933)
table(telco_phone$churn)
phonetrainIndex = sample(1:nrow(telco_phone), size=round(0.75*nrow(telco_phone)), replace=FALSE)
phonetrain <- telco_phone[phonetrainIndex,]
phonetest  <- telco_phone[-phonetrainIndex,]
dim(phonetrain);dim(phonetest)
logitphonelm1 <- glm(churn ~ tenure + contract, family=binomial (link="probit"),data=phonetrain)
summary(logitphonelm1)
phonetestlm1 <- phonetest[ , c(1:13)]
predlogitphonelm1 <-predict(logitphonelm1, newdata=phonetestlm1,type="response")
hist(predlogitphonelm1,ylim=c(0,600),xlim = c(0,0.26))
predlogitphonelm1 <- ifelse(predlogitphonelm1>0.07, 1, 0)
predlogitphonelm1
table(phonetest$churn,predlogitphonelm1)
hist(predlogitphonelm1,ylim=c(0,1000),main="Churn Predictions on Test Data Set")
abline(h = 256, col="mediumpurple", lwd=3, lty=3)
abline(h = 124, col="mediumpurple", lwd=3, lty=3)
# Verified by hand as well
ClassificationErrorPhoneLM1 <- round(mean(predlogitphonelm1 != phonetest$churn),3)
print(paste("Accuracy = ", 1-ClassificationErrorPhoneLM1))
phonelm1sensitivity <- round(InformationValue::sensitivity(phonetest$churn,predlogitphonelm1),3)
print(paste("Recall = ",phonelm1sensitivity))
phonelm1precision <- round(InformationValue::precision(phonetest$churn,predlogitphonelm1),3)
print(paste("Precision = ",phonelm1precision))
F1phone <- round((2 * phonelm1sensitivity * phonelm1precision) / (phonelm1sensitivity + phonelm1precision),3)
print(paste("F1 Score = ",F1phone))
prephonelm1 <- prediction(predlogitphonelm1, phonetest$churn)
perfphonelm1 <- performance(prephonelm1, measure = "tpr", x.measure = "fpr")
plot(perfphonelm1)
aucphonelm1 <- performance(prephonelm1, measure = "auc")
aucphonelm1 <- aucphonelm1@y.values[[1]]
aucphonelm1 <- round(aucphonelm1,3)
aucphonelm1
telco_intnet <- subset(orig_telco,phoneservice=="No" & internetservice!="No")
unique(telco_intnet$phoneservice)
unique(telco_intnet$internetservice)
cor(telco_intnet$tenure,telco_intnet$churn)
#Clean up the data by making monthlycharges categorical data instead of continuous data
telco_intnet <- telco_intnet %>%
mutate(mthlychrgcat = if_else(monthlycharges< median(telco_intnet$monthlycharges), "Less than Median", "More than Median"))
telco_intnet$mthlychrgcat=as.factor(telco_intnet$mthlychrgcat)
telco_intnet = subset(telco_intnet, select = -c(phoneservice,multiplelines,monthlycharges) )
#Check for NA rows and remove if small number of rows are affected
names(which(colSums(is.na(telco_intnet))>0))
telco_intnet<-telco_intnet[!(is.na(telco_intnet[["totalcharges"]])),]
names(which(colSums(is.na(telco_intnet))>0))
#Calculate the percentage of customers who churn
sum(telco_intnet$churn == "1")/nrow(telco_intnet)*100
str(telco_intnet)
intnetglm1 <- glm(churn ~ tenure + contract + onlinesecurity + onlinebackup + deviceprotection + techsupport + streamingtv + streamingmovies, family=binomial (link="logit"),data=telco_intnet)
summary(intnetglm1)
# AIC = 596.46
intnetglm2 <- glm(churn ~ tenure + contract + partner + mthlychrgcat + dependents + totalcharges  + seniorcitizen + onlinesecurity +techsupport, family=binomial (link="logit"),data=telco_intnet)
summary(intnetglm2)
# AIC = 583.34
intnetglm3 <- glm(churn ~ tenure + contract, family=binomial (link="logit"),data=telco_intnet)
summary(intnetglm3)
# AIC = 615.21
intnetglm4 <- glm(churn ~ tenure + contract, family=binomial (link="probit"),data=telco_intnet)
summary(intnetglm3)
# AIC = 604.6
stargazer(intnetglm1, intnetglm2, intnetglm3,intnetglm4, title="Logit/Probit Internet Only Customer Churn Comparison", type="text")
set.seed(6933)
table(telco_intnet$churn)
intnettrainIndex = sample(1:nrow(telco_intnet), size=round(0.75*nrow(telco_intnet)), replace=FALSE)
intnettrain <- telco_intnet[intnettrainIndex,]
intnettest  <- telco_intnet[-intnettrainIndex,]
dim(intnettrain);dim(intnettest)
logitintnetlm1 <- glm(churn ~ tenure  + contract+ techsupport, family=binomial (link="probit"),data=intnettrain)
summary(logitintnetlm1)
intnettestlm1 <- intnettest[ , c(1:18)]
predlogitintnetlm1 <-predict(logitintnetlm1, newdata=intnettestlm1,type="response")
hist(predlogitintnetlm1,ylim=c(0,100),xlim = c(0,0.7))
predlogitintnetlm1 <- ifelse(predlogitintnetlm1>0.25, 1, 0)
predlogitintnetlm1
table(intnettest$churn,predlogitintnetlm1)
hist(predlogitintnetlm1,ylim=c(0,1000),main="Churn Predictions on Test Data Set")
abline(h = 101, col="mediumpurple", lwd=3, lty=3)
abline(h = 69, col="mediumpurple", lwd=3, lty=3)
ClassificationErrorIntNetLM1 <- round(mean(predlogitintnetlm1 != intnettest$churn),3)
print(paste("Accuracy = ", 1-ClassificationErrorIntNetLM1))
intnetlm1sensitivity <- round(InformationValue::sensitivity(intnettest$churn,predlogitintnetlm1),3)
print(paste("Recall = ",intnetlm1sensitivity))
intnetlm1precision <- round(InformationValue::precision(intnettest$churn,predlogitintnetlm1),3)
print(paste("Precision = ",intnetlm1precision))
F1internet <- round((2 * intnetlm1sensitivity * intnetlm1precision) / (intnetlm1sensitivity + intnetlm1precision),3)
print(paste("F1 Score = ",F1internet))
preintnetlm1 <- prediction(predlogitintnetlm1, intnettest$churn)
perfintnetlm1 <- performance(preintnetlm1, measure = "tpr", x.measure = "fpr")
plot(perfintnetlm1)
aucintnetlm1 <- performance(preintnetlm1, measure = "auc")
aucintnetlm1 <- aucintnetlm1@y.values[[1]]
aucintnetlm1 <- round(aucintnetlm1,3)
aucintnetlm1
telco_both <- subset(orig_telco,phoneservice=="Yes" & internetservice!="No")
unique(telco_both$phoneservice)
unique(telco_both$internetservice)
#Clean up the data by making monthlycharges categorical data instead of continuous data
telco_both <- telco_both %>%
mutate(mthlychrgcat = if_else(monthlycharges< median(telco_both$monthlycharges), "Less than Median", "More than Median"))
telco_both$mthlychrgcat=as.factor(telco_both$mthlychrgcat)
telco_both = subset(telco_both, select = -c(monthlycharges) )
#Check for NA rows and remove if small number of rows are affected
names(which(colSums(is.na(telco_both))>0))
telco_both<-telco_both[!(is.na(telco_both[["totalcharges"]])),]
names(which(colSums(is.na(telco_both))>0))
#Calculate the percentage of customers who churn
sum(telco_both$churn == "1")/nrow(telco_both)*100
str(telco_both)
cor(telco_both$tenure,telco_both$churn)
bothglm1 <- glm(churn ~ tenure + contract + mthlychrgcat, family=binomial (link="logit"),data=telco_both)
summary(bothglm1)
# AIC = 4946
bothglm2 <- glm(churn ~ partner + dependents + tenure + contract, family=binomial (link="logit"),data=telco_both)
summary(bothglm2)
# AIC = 5088
bothglm3 <- glm(churn ~ tenure + contract, family=binomial (link="logit"),data=telco_both)
summary(bothglm3)
# AIC = 5100.2
bothglm4 <- glm(churn ~ tenure + contract, family=binomial (link="probit"),data=telco_both)
summary(bothglm4)
stargazer(bothglm1, bothglm2, bothglm3, bothglm4, title="Logit/Probit Both-Service Customer Churn Comparison", type="text")
set.seed(6933)
table(telco_both$churn)
bothtrainIndex = sample(1:nrow(telco_both), size=round(0.75*nrow(telco_both)), replace=FALSE)
bothtrain <- telco_both[bothtrainIndex,]
bothtest  <- telco_both[-bothtrainIndex,]
dim(bothtrain);dim(bothtest)
logitbothlm1 <- glm(churn ~ tenure + contract + dependents + mthlychrgcat, family=binomial (link="probit"),data=bothtrain)
summary(logitbothlm1)
bothtestlm1 <- bothtest[ , c(1:20)]
predlogitbothlm1 <-predict(logitbothlm1, newdata=bothtestlm1,type="response")
hist(predlogitbothlm1,ylim=c(0,400),xlim = c(0,0.8))
predlogitbothlm1 <- ifelse(predlogitbothlm1>0.35, 1, 0)
predlogitbothlm1
table(bothtest$churn,predlogitbothlm1)
hist(predlogitbothlm1,ylim=c(0,1000),main="Churn Predictions on Test Data Set")
abline(h = 643, col="mediumpurple", lwd=3, lty=3)
abline(h = 565, col="mediumpurple", lwd=3, lty=3)
ClassificationErrorBothLM1 <- round(mean(predlogitbothlm1 != bothtest$churn),3)
print(paste("Accuracy = ", 1-ClassificationErrorBothLM1))
bothlm1sensitivity <- round(InformationValue::sensitivity(bothtest$churn,predlogitbothlm1),3)
print(paste("Recall = ",bothlm1sensitivity))
bothlm1precision <- round(InformationValue::precision(bothtest$churn,predlogitbothlm1),3)
print(paste("Precision = ",bothlm1precision))
F1both <- round((2 * bothlm1sensitivity * bothlm1precision) / (bothlm1sensitivity + bothlm1precision),3)
print(paste("F1 Score = ",F1both))
prebothlm1 <- prediction(predlogitbothlm1, bothtest$churn)
perfbothlm1 <- performance(prebothlm1, measure = "tpr", x.measure = "fpr")
plot(perfbothlm1)
aucbothlm1 <- performance(prebothlm1, measure = "auc")
aucbothlm1 <- aucbothlm1@y.values[[1]]
aucbothlm1 <- round(aucbothlm1,3)
aucbothlm1
rm(list=ls())
library(rio)
library(survival)
library(survminer)
library(stargazer)
lungc <- import("LungCancer.xlsx")
colnames(lungc)=tolower(make.names(colnames(lungc)))
lungc <- import("Assignment 2 - Problem 2 - LungCancer.xlsx")
colnames(lungc)=tolower(make.names(colnames(lungc)))
str(lungc)
attach(lungc)
table(status)
# Question 1
kmlungc1 <- survfit(Surv(survivaldays, status) ~ 1)
kmlungc1
# mark.time=TRUE shows the censored observations on the graph with tick marks
plot(kmlungc1, xlab="Survival Days", conf.int=F,ylab="Survival Probability",mark.time=TRUE, col="steelblue", main='Survival Probabilities for All Participants',lwd=2)
abline(v = 183, col="mediumpurple", lwd=2, lty=3)
abline(v = 365, col="mediumpurple", lwd=2, lty=3)
abline(h=0.5, col="mediumpurple",lty=2)
kmlungc2 <- survfit(Surv(survivaldays, status) ~ treatment)
kmlungc2
summary(kmlungc2)
# steelblue = treatment of 1 (standard)/ blue = treatment of 2 (test)
# mark.time=TRUE shows the censored observations on the graph with tick marks
plot(kmlungc2, xlab="Survival Days", conf.int=F,ylab="Survival Probability",mark.time=TRUE,main='Survival Probabilities Based on Treatment Type', col=c("steelblue","hotpink3"),lwd=2)
legend(400,1, legend=c("No Treatment","Test Treatment"), lty=1,lwd=2,col=c("steelblue","hotpink3"),bty="",cex=1.5)
abline(v = 183, col="mediumpurple", lwd=2, lty=3)
abline(v = 365, col="mediumpurple", lwd=2, lty=3)
abline(h=0.11, col="hotpink3",lty=2)
abline(h=0.07, col="steelblue",lty=2)
abline(h=0.215, col="magenta",lty=2)
# Log-Rank-Test / Ho: survival in the two groups is the same / Ha: survival is not the same
survdiff(Surv(survivaldays, status) ~ treatment)
# mean number of days where a patient can be expected to survive if they are on the standard vs the test treatment
standard_treat <- subset(lungc,treatment=="1")
test_treat <- subset(lungc,treatment=="2")
mean(standard_treat$survivaldays)
mean(test_treat$survivaldays)
# Question 2
coxlungc <- coxph(Surv(survivaldays, status) ~ treatment + ageinyrs + monthsfromdiagnosis, data=lungc, method="breslow")
summary(coxlungc)
explungc <- survreg(Surv(survivaldays, status) ~ treatment + ageinyrs + monthsfromdiagnosis, data=lungc, dist="exponential")
summary(explungc)
weibulllungc <- survreg(Surv(survivaldays, status) ~ treatment + ageinyrs + monthsfromdiagnosis, data=lungc, dist="weibull")
summary(weibulllungc)
loglogisticlungc <- survreg(Surv(survivaldays, status) ~ treatment + ageinyrs + monthsfromdiagnosis, data=lungc, dist="loglogistic")
summary(loglogisticlungc)
stargazer(coxlungc, explungc, weibulllungc, loglogisticlungc, type="text")
rm(list=ls())
library(rio)
library(conflicted)
library(dplyr)
library(car)
library(corrplot)
library(lubridate)
library(tidyverse)
library(lattice)
library(stargazer)
library(plm)
library(lme4)
rawproductsdf <- import("Final Exam - SnackChain.xlsx", sheet = "products")
colnames(rawproductsdf)=tolower(make.names(colnames(rawproductsdf)))
# View(rawproductsdf)
productsdf <- subset(rawproductsdf, category!="ORAL HYGIENE PRODUCTS")
productsdf <- cbind(productsdf, size_in_oz= gsub(' OZ','',productsdf$product_size))
productsdf$size_in_oz <- as.numeric(productsdf$size_in_oz)
productsdf = subset(productsdf, select = -c(product_size) )
rm(rawproductsdf)
# View(productsdf)
str(productsdf)
storesdf <- import("SnackChain.xlsx", sheet = "stores")
colnames(storesdf)=tolower(make.names(colnames(storesdf)))
storesdf <- import("Final Exam - SnackChain.xlsx", sheet = "stores")
colnames(storesdf)=tolower(make.names(colnames(storesdf)))
storesdf = subset(storesdf, select = -c(parking) )
names(storesdf)[names(storesdf) == 'store_id'] <- 'store_num'
storesdf<-storesdf[!(storesdf$store_num=="4503" & storesdf$segment=="MAINSTREAM"),]
storesdf<-storesdf[!(storesdf$store_num=="17627" & storesdf$segment=="UPSCALE"),]
storesdf
unique(storesdf$store_num)
transactionssdf <- import("SnackChain.xlsx", sheet = "transactions")
colnames(transactionssdf)=tolower(make.names(colnames(transactionssdf)))
transactionssdf <- import("Final Exam - SnackChain.xlsx", sheet = "transactions")
colnames(transactionssdf)=tolower(make.names(colnames(transactionssdf)))
transactionssdf$week_end_date <- as.Date(transactionssdf$week_end_date)
str(transactionssdf)
# Remove the few rows with missing price data
which(colSums(is.na(transactionssdf))>0)
names(which(colSums(is.na(transactionssdf))>0))
transactionssdf <- transactionssdf[!(is.na(transactionssdf[["price"]])),]
transactionssdf <- transactionssdf[!(is.na(transactionssdf[["base_price"]])),]
transactionssdf <- transactionssdf[!(transactionssdf$price=="0"),]
which(colSums(is.na(transactionssdf))>0)
names(which(colSums(is.na(transactionssdf))>0))
# Calculate the year quarter
#transactionssdf$year_quarter=year(transactionssdf$week_end_date), "/0",quarter(transactionssdf$week_end_date));
transactionssdf <- cbind(transactionssdf, year=0)
transactionssdf$year=year(transactionssdf$week_end_date)
transactionssdf <- cbind(transactionssdf, quarter=0)
transactionssdf$quarter=quarter(transactionssdf$week_end_date)
transactionssdf <- cbind(transactionssdf, month=0)
transactionssdf$month=month(transactionssdf$week_end_date)
# Create a time index based on the ordered week
weekindexdf <- unique(transactionssdf[,'week_end_date',drop = FALSE])
weekindexdf[order(as.Date(weekindexdf$week_end_date, format="%Y-%m-%d")),]
weekindexdf$weekid <- seq.int(nrow(weekindexdf))
indexedtrxdf <- merge(transactionssdf, weekindexdf, by = "week_end_date")
# Build the combined data set
df <- merge(productsdf, indexedtrxdf, by = "upc")
df <- cbind(df, price_per_oz = round(df$price / df$size_in_oz,2))
df <- merge(df, storesdf, by = "store_num")
rm(indexedtrxdf)
# rm(productsdf)  # needed at the end to get product details on elasticity
rm(transactionssdf)
rm(storesdf)
rm(weekindexdf)
which(colSums(is.na(df))>0)
names(which(colSums(is.na(df))>0))
df$store_num <- as.factor(df$store_num)
df$upc       <- as.factor(df$upc)
df$category  <- as.factor(df$category)
df$city     <- as.factor(df$city)
df$segment   <- as.factor(df$segment)
df$category  <- relevel(df$category, "BAG SNACKS")
df$segment   <- relevel(df$segment, "VALUE")
str(df)
# Looking for duplicate keys
is.pbalanced(df)
df$unique_id <- paste(df$store_num,df$upc,df$week_end_date) # concatenate to make unique ID
df$duplicate = duplicated(df$unique_id) # generate the duplicate variable
subset(df, duplicate=="TRUE") # find the duplicate
attach(df)
head(df[,c(8,18:20)])
tail(df[,c(8,18:20)])
# Test for relationship between time and spend/units/visits
spend_lm <- lm(spend ~ weekid, data=df)
summary(spend_lm)
units_lm <- lm(units ~ weekid, data=df)
summary(units_lm)
hhs_lm <- lm(hhs ~ weekid, data=df)
summary(hhs_lm)
# No autocorrelation
durbinWatsonTest(spend_lm)  # 1.789 -> no autocorrelation
pacf(df$spend)              # graph confirms
durbinWatsonTest(units_lm)  # 1.832 -> no autocorrelation
pacf(df$units)              # graph confirms
durbinWatsonTest(hhs_lm)    # 1.812 -> no autocorrelation
pacf(df$hhs)                # graph confirms
plot(spend ~ weekid, data=df,type="o")
abline(spend_lm, col="magenta",lwd=2)
par(mfrow=c(2,2))
plot(spend_lm)
plot(units_lm)
plot(hhs_lm)
par(mfrow=c(1,1))
# No seasonal trend detected
par(mfrow=c(2,2))
plot(weekid,spend,type="o")
plot(weekid,units,type="o")
plot(weekid,visits,type="o")
par(mfrow=c(1,1))
# Data is showing exponential/highly rightly skewed
hist(spend,breaks=50,xlim=c(0,500),ylim=c(0,500000))
mean(spend) #64
median(spend)  # 43
hist(units,breaks=75,xlim=c(0,200),ylim=c(0,420000))
mean(units) # 23
median(units) # 15
hist(hhs,breaks=50,xlim=c(0,500),ylim=c(0,420000))
mean(hhs) #20
median(hhs) # 13
# Correlation check
round(cor(cbind(df[, 9:22],df[,"msa"],df[, 28:29])), 3)
corcols <- cor(cbind(df[, 9:22],df[,"msa"],df[, 28:29]))
corrplot(corcols, method="circle",type="lower")
# Research for heterogeneity based on segment and category
densityplot(~spend | segment*category, data=df, col="steelblue")
densityplot(~units | segment*category, data=df, col="steelblue")
densityplot(~hhs | segment*category, data=df, col="steelblue")
bwplot(spend ~ segment | category, data=df)
bwplot(units ~ segment | category, data=df)
bwplot(hhs ~ segment | category, data=df)
xyplot(spend ~ segment | category, data=df)
xyplot(units ~ segment | category, data=df)
xyplot(hhs ~ segment | category, data=df)
#  1.	What is the effect of promotions, displays, or being featured in the circular on product sales (spend), unit sales, and the number of household purchasers?
pooled_spend1 <- plm(spend ~ tpr_only + display + feature, data=df, model="pooling")
summary(pooled_spend1)
fixed_spend1 <-  plm(spend ~ tpr_only + display + feature, data=df, model="within")
summary(fixed_spend1)
fixef(fixed_spend1)
summary(fixef(fixed_spend1))
random_spend1 <- plm(spend ~ tpr_only + display + feature, data=df, model="random")
summary(random_spend1)
ranef(random_spend1)
summary(ranef(random_spend1))
plmtest(pooled_spend1)
plmtest(pooled_spend1, effect="twoways", type="bp")
pFtest(fixed_spend1, pooled_spend1)
phtest(fixed_spend1, random_spend1)
stargazer(pooled_spend1, fixed_spend1, random_spend1, type="text", single.row=TRUE)
pooled_units1 <- plm(units ~ tpr_only + display + feature, data=df, model="pooling")
summary(pooled_units1)
fixed_units1 <-  plm(units ~ tpr_only + display + feature, data=df, model="within")
summary(fixed_units1)
fixef(fixed_units1)
summary(fixef(fixed_units1))
random_units1 <- plm(units ~ tpr_only + display + feature, data=df, model="random")
summary(random_units1)
ranef(random_units1)
summary(ranef(random_units1))
plmtest(pooled_units1)
plmtest(pooled_units1, effect="twoways", type="bp")
pFtest(fixed_units1, pooled_units1)
phtest(fixed_units1, random_units1)
stargazer(pooled_units1, fixed_units1, random_units1, type="text", single.row=TRUE)
pooled_hhs1 <- plm(hhs ~ tpr_only + display + feature, data=df, model="pooling")
summary(pooled_hhs1)
fixed_hhs1 <-  plm(hhs ~ tpr_only + display + feature, data=df, model="within")
summary(fixed_hhs1)
fixef(fixed_hhs1)
summary(fixef(fixed_hhs1))
random_hhs1 <- plm(hhs ~ tpr_only + display + feature, data=df, model="random")
summary(random_hhs1)
ranef(random_hhs1)
summary(ranef(random_hhs1))
plmtest(pooled_hhs1)
plmtest(pooled_hhs1, effect="twoways", type="bp")
pFtest(fixed_hhs1, pooled_hhs1)
phtest(fixed_hhs1, random_hhs1)
stargazer(pooled_hhs1, fixed_hhs1, random_hhs1, type="text", single.row=TRUE)
idxdf <- pdata.frame(df, index=c("weekid","store_num","upc"))
pooled_spend2 <- plm(spend ~ tpr_only + display + feature + size + price + category + segment, data=idxdf, model="pooling")
summary(pooled_spend2)
fixed_spend2 <-  plm(spend ~ tpr_only + display + feature + size + price + category + segment, data=idxdf, model="within")
summary(fixed_spend2)
fixef(fixed_spend2)
summary(fixef(fixed_spend2))
random_spend2 <- plm(spend ~ tpr_only + display + feature + size + price + category + segment, data=idxdf, model="random")
# random_spend2  <- lmer(spend ~ tpr_only + display + feature + size + price + (1|category) + (1|segment), data=idxdf, REML=FALSE)
summary(random_spend2)
ranef(random_spend2)
summary(ranef(random_spend2))
plmtest(pooled_spend2)
pFtest(fixed_spend2, pooled_spend2)
phtest(fixed_spend2, random_spend2)
stargazer(pooled_spend2, fixed_spend2, random_spend2, type="text", single.row=TRUE)
summary(fixef(fixed_spend2))
pooled_units2 <- plm(units ~ tpr_only + display + feature + size + price + category + segment, data=idxdf, model="pooling")
summary(pooled_units2)
fixed_units2 <-  plm(units ~ tpr_only + display + feature + size + price + category + segment, data=idxdf, model="within")
summary(fixed_units2)
fixef(fixed_units2)
summary(fixef(fixed_units2))
random_units2 <- plm(units ~ tpr_only + display + feature + size + price + category + segment, data=idxdf, model="random")
summary(random_units2)
ranef(random_units2)
summary(ranef(random_units2))
plmtest(pooled_units2)
pFtest(fixed_units2, pooled_units2)
phtest(fixed_units2, random_units2)
stargazer(pooled_units2, fixed_units2, random_units2, type="text", single.row=TRUE)
summary(fixef(fixed_units2))
pooled_hhs2 <- plm(hhs ~ tpr_only + display + feature + size + price + category + segment, data=idxdf, model="pooling")
summary(pooled_hhs2)
fixed_hhs2 <-  plm(hhs ~ tpr_only + display + feature + size + price + category + segment, data=idxdf, model="within")
summary(fixed_hhs2)
fixef(fixed_hhs2)
summary(fixef(fixed_hhs2))
random_hhs2 <- plm(hhs ~ tpr_only + display + feature + size + price + category + segment, data=idxdf, model="random")
summary(random_hhs2)
ranef(random_hhs2)
summary(ranef(random_hhs2))
plmtest(pooled_hhs2)
pFtest(fixed_hhs2, pooled_hhs2)
phtest(fixed_hhs2, random_hhs2)
stargazer(pooled_hhs2, fixed_hhs2, random_hhs2, type="text", single.row=TRUE)
summary(fixef(fixed_hhs2))
#  3.	What are the five most prices elastic and five least price-elastic products?
#  Price elasticity is the change in sales for a unit change in product price.
#  4.	As the retailer, which products would you lower the price to maximize (a) product sales and (b) unit sales, and why?
rm(upcdf)
upcdf <- unique(df[,'upc',drop = FALSE])
upcdf$upc <- as.character(upcdf$upc)
upcdf <- cbind(upcdf, log_price_coef=0, log_units_coef=0)
View(upcdf)
head(upcdf)
str(upcdf)
for (i in 1:nrow(upcdf)) {
upcnumber <- upcdf[i ,1]
spenddf <- lm(log(spend) ~ log(price) + store_num,data = df, subset=(upc==upcnumber))
spendcoeff <- spenddf$coefficients["log(price)"]
upcdf$log_price_coef[upcdf$upc == upcnumber] <- round(spendcoeff,3)
unitdf <- lm(log(units) ~ log(price) + store_num,data = df, subset=(upc==upcnumber))
unitcoeff <- unitdf$coefficients["log(price)"]
upcdf$log_units_coef[upcdf$upc == upcnumber] <- round(unitcoeff,3)
}
price_elasticity <- merge(productsdf, upcdf, by = "upc")
pricesort <- price_elasticity[order(price_elasticity$log_price_coef),]
upc_price_elasticity = subset(pricesort, select = -c(log_units_coef,category,sub_category) )
head(upc_price_elasticity)
tail(upc_price_elasticity,n=10)
unit_elasticity <- merge(productsdf, upcdf, by = "upc")
unitsort <- unit_elasticity[order(unit_elasticity$log_units_coef),]
upc_units_elasticity = subset(unitsort, select = -c(log_price_coef,category,sub_category) )
head(upc_units_elasticity)
tail(upc_units_elasticity,n=10)
#Export to present in report nicely (with grids)
write.csv(upc_price_elasticity,file="price_elasticity.csv")
write.csv(upc_units_elasticity,file="unit_elasticity.csv")
rm(list=ls())
library(rio)
library(moments)
mydata=import("Assignment Data.xlsx")
attach(mydata)
str(mydata)
mydata
head(mydata)
tail(mydata)
mydata=import("Assignment Data.xlsx")
mydata=import("./Assignment Data.xlsx")
mydata=import(".Assignment Data.xlsx")
mydata=import(".\Assignment Data.xlsx")
