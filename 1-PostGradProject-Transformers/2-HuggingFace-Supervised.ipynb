{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e46bd385",
   "metadata": {},
   "source": [
    "# File Loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dda0c89a-c2b0-43d8-bf63-1f97731dfe61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other GPU memory troubleshooting commands\n",
    "#import torch\n",
    "#torch.cuda.memory_stats() \n",
    "#torch.cuda.empty_cache()\n",
    "#torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7608e063-daa6-4599-9c2c-c7a0f63600b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Needed to avoid running out of GPU memory\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:256\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "22a6f5ea-25c1-42f4-9380-58c8407b1c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/littlepenguin/anaconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Sun Oct 22 14:53:31 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.116.04   Driver Version: 525.116.04   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 40%   29C    P8    11W / 170W |   4049MiB / 12288MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1170      G   /usr/lib/xorg/Xorg                  9MiB |\n",
      "|    0   N/A  N/A      1282      G   /usr/bin/gnome-shell                3MiB |\n",
      "|    0   N/A  N/A      2517      C   /usr/bin/python3                 4032MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d8534764-89a3-493f-baff-4d9d9cb17ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bf95b729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 28000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 12000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "imdb_ds_dict = load_dataset(\"csv\", data_files=\"movie.csv\")\n",
    "imdb_ds = imdb_ds_dict['train']\n",
    "imdb_ds = imdb_ds.train_test_split(test_size=0.3)\n",
    "imdb_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b014baf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 28000\n",
       "})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_train_ds = imdb_ds[\"train\"]\n",
    "imdb_train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a8bee324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 12000\n",
       "})"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_test_ds = imdb_ds[\"test\"]\n",
    "imdb_test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0245182",
   "metadata": {},
   "source": [
    "# Configuration\n",
    "\n",
    "Each model configuration has different attributes; for instance, all NLP models have the hidden_size, num_attention_heads, num_hidden_layers and vocab_size attributes in common. These attributes specify the number of attention heads or hidden layers to construct a model with.\n",
    "\n",
    "These are the default DistilBert configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "11a77211",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "356b31db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.31.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = BertConfig()\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e099c778",
   "metadata": {},
   "source": [
    "The code below changes the activation method and the dropout rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6b4d3e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertConfig {\n",
      "  \"activation\": \"relu\",\n",
      "  \"attention_dropout\": 0.4,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.31.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_config = BertConfig(activation=\"relu\", attention_dropout=0.4)\n",
    "print(my_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f94f35",
   "metadata": {},
   "source": [
    "Once the model is configured, it can be saved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b1ca1207",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_config.save_pretrained(save_directory=\"./Bert-HuggingFace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6471265",
   "metadata": {},
   "source": [
    "# Model Creation\n",
    "\n",
    "The model defines what each layer is doing and what operations are happening. Attributes like num_hidden_layers from the configuration are used to define the architecture. Every model shares the base class PreTrainedModel and a few common methods like resizing input embeddings and pruning self-attention heads. \n",
    "\n",
    "Load your custom configuration attributes into the model.  For sentiment analysis, the Sequence Classification variation is needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "de827f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "model = BertForSequenceClassification(my_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0490214a",
   "metadata": {},
   "source": [
    "This creates a model with random values instead of pretrained weights. You wonâ€™t be able to use this model for anything useful yet until you train it. Training is a costly and time-consuming process. It is generally better to use a pretrained model to obtain better results faster, while using only a fraction of the resources required for training.\n",
    "\n",
    "At this point, you have a base BERT model which outputs the hidden states. The hidden states are passed as inputs to a model head to produce the final output. ðŸ¤— Transformers provides a different model head for each task as long as a model supports the task (i.e., you canâ€™t use DistilBERT for a sequence-to-sequence task like translation).\n",
    "\n",
    "The last base class you need before using a model for textual data is a tokenizer to convert raw text to tensors. There are two types of tokenizers you can use with ðŸ¤— Transformers:\n",
    "    - PreTrainedTokenizer: a Python implementation of a tokenizer.\n",
    "    - PreTrainedTokenizerFast: a tokenizer from our Rust-based ðŸ¤— Tokenizer library.\n",
    "    \n",
    "If you trained your own tokenizer, you can create one from your vocabulary file:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2dbdf3",
   "metadata": {},
   "source": [
    "It is important to remember the vocabulary from a custom tokenizer will be different from the vocabulary generated by a pretrained modelâ€™s tokenizer. You need to use a pretrained modelâ€™s vocabulary if you are using a pretrained model, otherwise the inputs wonâ€™t make sense. Create a tokenizer with a pretrained modelâ€™s vocabulary with the BertTokenizer class.\n",
    "\n",
    "Now that you have instantiated a tokenizer, create a function that will tokenize the text. You should also truncate longer sequences in the text to be no longer than the modelâ€™s maximum input length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3a3d3f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "my_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Using the vocab file from the wikipedia data set resulted in bad results.  Used the matching Bert AutoTokenizer to get a working model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acde479-1e26-455a-8e9f-e517203ebc6d",
   "metadata": {},
   "source": [
    "It is important to remember the vocabulary from a custom tokenizer will be different from the vocabulary generated by a pretrained modelâ€™s tokenizer. You need to use a pretrained modelâ€™s vocabulary if you are using a pretrained model, otherwise the inputs wonâ€™t make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "03325447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return my_tokenizer(examples[\"text\"], padding=True, truncation=True,max_length=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "16685f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af0c61ac20944bb827d3d927e4982a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/28000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76e383107ca542359b772910b3c074cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use ðŸ¤— Datasets map function to apply the preprocessing function to the entire dataset. You can also set batched=True to \n",
    "#apply the preprocessing function to multiple elements of the dataset at once for faster preprocessing:\n",
    "\n",
    "tokenized_imdb_train = imdb_ds[\"train\"].map(preprocess_function, batched=True)\n",
    "tokenized_imdb_test = imdb_ds[\"test\"].map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "163b1d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 28000\n",
       "})"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_imdb_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0b6b03d9-2a4e-4d8e-9213-31fa6ed3c251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 12000\n",
       "})"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_imdb_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00ae61b",
   "metadata": {},
   "source": [
    "Lastly, pad your text so they are a uniform length. While it is possible to pad your text in the tokenizer function by setting padding=True, it is more efficient to only pad the text to the length of the longest element in its batch. This is known as dynamic padding. You can do this with the DataCollatorWithPadding function:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202dc303",
   "metadata": {},
   "source": [
    "# Fine-tune with TensorFlow\n",
    "\n",
    "Start by batching the processed examples together with dynamic padding using the DataCollatorWithPadding function. Make sure you set return_tensors=\"tf\" to return tf.Tensor outputs instead of PyTorch tensors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f3ac3742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(my_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba8d623",
   "metadata": {},
   "source": [
    "Next, convert your datasets to the tf.data.Dataset format with to_tf_dataset. Specify inputs and labels in the columns argument:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30710210-5bfc-4c6b-a4f8-b0980fb717d1",
   "metadata": {},
   "source": [
    "Define the metrics you will be using to evaluate how good is the fine-tuned model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "014e60e4-fd11-4b71-beb8-71d726c2d3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    " \n",
    "def compute_metrics(eval_pred):\n",
    "   load_accuracy = load_metric(\"accuracy\")\n",
    "   load_f1 = load_metric(\"f1\")\n",
    "  \n",
    "   logits, labels = eval_pred\n",
    "   predictions = np.argmax(logits, axis=-1)\n",
    "   accuracy = load_accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "   f1 = load_f1.compute(predictions=predictions, references=labels)[\"f1\"]\n",
    "   return {\"accuracy\": accuracy, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ec02d260",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a059b15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "14cc6815",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_imdb_train,\n",
    "    eval_dataset=tokenized_imdb_test,\n",
    "    tokenizer=my_tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a2368de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/littlepenguin/.local/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8750' max='8750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8750/8750 16:09, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.707000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.707700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.681100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.598400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.526200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.520900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.508700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.452700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.441000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.447900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.416900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.399500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.394500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.390900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.357200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.355300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.357900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8750, training_loss=0.4820475533621652, metrics={'train_runtime': 969.2456, 'train_samples_per_second': 144.442, 'train_steps_per_second': 9.028, 'total_flos': 3597221460000000.0, 'train_loss': 0.4820475533621652, 'epoch': 5.0})"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5bfc0a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [750/750 00:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5219933390617371,\n",
       " 'eval_accuracy': 0.7640833333333333,\n",
       " 'eval_f1': 0.7613990729034977,\n",
       " 'eval_runtime': 21.3179,\n",
       " 'eval_samples_per_second': 562.907,\n",
       " 'eval_steps_per_second': 35.182,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "129f8e7d-4d60-4619-b927-88b72c4a4b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./Bert-HuggingFace/finetune-imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2a9c1436-705b-4b66-8912-ef88ee70fc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_0', 'score': 0.8385729789733887},\n",
       " {'label': 'LABEL_0', 'score': 0.8936507105827332},\n",
       " {'label': 'LABEL_0', 'score': 0.9752849340438843}]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "sentiment_classification = pipeline('text-classification',\"/home/littlepenguin/Git/MS-BAIS/2023-08-IndStudy-Transformers/HuggingFace/Bert-HuggingFace/finetune-imdb\")\n",
    "\n",
    "sentiment_classification([\"I don't know\", \n",
    "                          \"I don't care\",\n",
    "                          \"I hate horror movies\"])\n",
    "\n",
    "# LABEL_0 = negative\n",
    "# LABEL_1 = positive\n",
    "\n",
    "#  These were also labeled as negative in the unsupervised model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b04bec5e-349c-46c0-853a-3a5269109a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.978111743927002},\n",
       " {'label': 'LABEL_1', 'score': 0.9714835286140442},\n",
       " {'label': 'LABEL_1', 'score': 0.9659692049026489},\n",
       " {'label': 'LABEL_1', 'score': 0.9689449667930603},\n",
       " {'label': 'LABEL_1', 'score': 0.9133505821228027},\n",
       " {'label': 'LABEL_1', 'score': 0.9779731631278992}]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_classification([\"So great; I loved it!\",\n",
    "                            \"This is average!\",\n",
    "                            \"This is average\",\n",
    "                            \"This is a nightmare!\",\n",
    "                            \"This is a dream!\",\n",
    "                            \"I love my dog\"])\n",
    "\n",
    "#  These were also labeled as positive in the unsupervised model.  The scores are different.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf22357-79c1-41d5-bf63-519d8946c8be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
