{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 3 Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we will focus on healthcare. This data set is made available by MIT. It contains data about 9,026 heartbeat measurements. Each row represents a single measurement (captured on a timeline). There are a total of 80 data points (columns). This is a multiclass classification task: predict whether the measurement represents a normal heartbeat or other anomalies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of Variables\n",
    "\n",
    "You will use the **hearbeat_cleaned.csv** data set for this assignment. Each row represents a single measurement. Columns labeled as T1 from T80 are the time steps on the timeline (there are 80 time steps, each time step has only one measurement). \n",
    "\n",
    "The last column is the target variable. It shows the label (category) of the measurement as follows:<br>\n",
    "0 = Normal<br>\n",
    "1 = Supraventricular premature beat<br>\n",
    "2 = Premature ventricular contraction<br>\n",
    "3 = Fusion of ventricular and normal beat<br>\n",
    "4 = Unclassifiable beat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Use the data set **hearbeat_cleaned.csv** to predict the column called **Target**. The input variables are columns labeled as **T1 to T80**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission:\n",
    "\n",
    "Please save and submit this Jupyter notebook file. The correctness of the code matters for your grade. **Readability and organization of your code is also important.** You may lose points for submitting unreadable/undecipherable code. Therefore, use markdown cells to create sections, and use comments where necessary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Prepare the Data (1 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hbeat = pd.read_csv(\"heartbeat_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7960, 81)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hbeat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T1</th>\n",
       "      <th>T2</th>\n",
       "      <th>T3</th>\n",
       "      <th>T4</th>\n",
       "      <th>T5</th>\n",
       "      <th>T6</th>\n",
       "      <th>T7</th>\n",
       "      <th>T8</th>\n",
       "      <th>T9</th>\n",
       "      <th>T10</th>\n",
       "      <th>...</th>\n",
       "      <th>T72</th>\n",
       "      <th>T73</th>\n",
       "      <th>T74</th>\n",
       "      <th>T75</th>\n",
       "      <th>T76</th>\n",
       "      <th>T77</th>\n",
       "      <th>T78</th>\n",
       "      <th>T79</th>\n",
       "      <th>T80</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.987</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.461</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.1620</td>\n",
       "      <td>0.1470</td>\n",
       "      <td>0.1380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>0.1970</td>\n",
       "      <td>0.1960</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.1990</td>\n",
       "      <td>0.2010</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.2080</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.1330</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.0898</td>\n",
       "      <td>0.0703</td>\n",
       "      <td>0.0781</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1950</td>\n",
       "      <td>0.1910</td>\n",
       "      <td>0.1520</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.2110</td>\n",
       "      <td>0.2070</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.0961</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.0442</td>\n",
       "      <td>0.0416</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.0857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2260</td>\n",
       "      <td>0.2420</td>\n",
       "      <td>0.2440</td>\n",
       "      <td>0.2860</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.8160</td>\n",
       "      <td>0.9770</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0722</td>\n",
       "      <td>0.0567</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0284</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0851</td>\n",
       "      <td>0.0747</td>\n",
       "      <td>0.0515</td>\n",
       "      <td>0.0593</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.0361</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.8690</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1200</td>\n",
       "      <td>0.1040</td>\n",
       "      <td>0.0874</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4210</td>\n",
       "      <td>0.8030</td>\n",
       "      <td>0.9510</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.0628</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      T1     T2     T3      T4      T5      T6      T7      T8      T9  \\\n",
       "0  0.987  0.892  0.461  0.1130  0.1490  0.1900  0.1650  0.1620  0.1470   \n",
       "1  1.000  0.918  0.621  0.1330  0.1050  0.1250  0.1170  0.0898  0.0703   \n",
       "2  1.000  0.751  0.143  0.1040  0.0961  0.0519  0.0442  0.0416  0.0364   \n",
       "3  1.000  0.740  0.235  0.0464  0.0722  0.0567  0.0103  0.0155  0.0284   \n",
       "4  1.000  0.833  0.309  0.0191  0.1010  0.1200  0.1040  0.0874  0.0765   \n",
       "\n",
       "      T10  ...     T72     T73     T74     T75    T76     T77     T78    T79  \\\n",
       "0  0.1380  ...  0.1970  0.1970  0.1960  0.2030  0.201  0.1990  0.2010  0.205   \n",
       "1  0.0781  ...  0.1950  0.1910  0.1520  0.1720  0.207  0.2110  0.2070  0.207   \n",
       "2  0.0857  ...  0.2260  0.2420  0.2440  0.2860  0.468  0.8160  0.9770  0.452   \n",
       "3  0.0155  ...  0.0851  0.0747  0.0515  0.0593  0.067  0.0361  0.1210  0.451   \n",
       "4  0.0765  ...  0.2050  0.4210  0.8030  0.9510  0.467  0.0000  0.0519  0.082   \n",
       "\n",
       "      T80  Target  \n",
       "0  0.2080       0  \n",
       "1  0.1720       0  \n",
       "2  0.0519       0  \n",
       "3  0.8690       0  \n",
       "4  0.0628       0  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hbeat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = hbeat['Target']\n",
    "x = hbeat.drop('Target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target variables need to be an array with integer type\n",
    "train_y = np.array(train_y)\n",
    "test_y = np.array(test_y)\n",
    "\n",
    "# Set the target values are set to be integers\n",
    "train_y = train_y.astype(np.int32)\n",
    "test_y = test_y.astype(np.int32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 1, 4, 4, 0, 0, 4, 4, 0, 2, 0, 0, 2, 0, 2, 2, 0, 0,\n",
       "       4, 2, 4, 4, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert input variables to a 2-D array with float data type\n",
    "train_x= np.array(train_x)\n",
    "test_x= np.array(test_x)\n",
    "\n",
    "train_x = train_x.astype(np.float32)\n",
    "test_x = test_x.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 80)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.865 , 0.722 , 0.173 , ..., 0.308 , 0.323 , 0.312 ],\n",
       "       [1.    , 0.824 , 0.188 , ..., 0.308 , 0.308 , 0.312 ],\n",
       "       [1.    , 0.832 , 0.166 , ..., 0.275 , 0.281 , 0.267 ],\n",
       "       ...,\n",
       "       [0.    , 0.123 , 0.197 , ..., 1.    , 0.964 , 0.769 ],\n",
       "       [1.    , 0.918 , 0.625 , ..., 0.0546, 0.102 , 0.181 ],\n",
       "       [0.952 , 0.914 , 0.808 , ..., 0.237 , 0.237 , 0.245 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.reshape(train_x, (train_x.shape[0], train_x.shape[1], 1))\n",
    "test_x = np.reshape(test_x, (test_x.shape[0], test_x.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5572, 80, 1), (5572,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape, train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.865 ],\n",
       "        [0.722 ],\n",
       "        [0.173 ],\n",
       "        ...,\n",
       "        [0.308 ],\n",
       "        [0.323 ],\n",
       "        [0.312 ]],\n",
       "\n",
       "       [[1.    ],\n",
       "        [0.824 ],\n",
       "        [0.188 ],\n",
       "        ...,\n",
       "        [0.308 ],\n",
       "        [0.308 ],\n",
       "        [0.312 ]],\n",
       "\n",
       "       [[1.    ],\n",
       "        [0.832 ],\n",
       "        [0.166 ],\n",
       "        ...,\n",
       "        [0.275 ],\n",
       "        [0.281 ],\n",
       "        [0.267 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.    ],\n",
       "        [0.123 ],\n",
       "        [0.197 ],\n",
       "        ...,\n",
       "        [1.    ],\n",
       "        [0.964 ],\n",
       "        [0.769 ]],\n",
       "\n",
       "       [[1.    ],\n",
       "        [0.918 ],\n",
       "        [0.625 ],\n",
       "        ...,\n",
       "        [0.0546],\n",
       "        [0.102 ],\n",
       "        [0.181 ]],\n",
       "\n",
       "       [[0.952 ],\n",
       "        [0.914 ],\n",
       "        [0.808 ],\n",
       "        ...,\n",
       "        [0.237 ],\n",
       "        [0.237 ],\n",
       "        [0.245 ]]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the baseline (0.5 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DummyClassifier(strategy=&#x27;most_frequent&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DummyClassifier</label><div class=\"sk-toggleable__content\"><pre>DummyClassifier(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DummyClassifier(strategy='most_frequent')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "dummy_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Train Accuracy: 0.5847092605886576\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "dummy_train_pred = dummy_clf.predict(train_x)\n",
    "\n",
    "baseline_train_acc = accuracy_score(train_y, dummy_train_pred)\n",
    "\n",
    "print('Baseline Train Accuracy: {}' .format(baseline_train_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Test Accuracy: 0.5757956448911222\n"
     ]
    }
   ],
   "source": [
    "dummy_test_pred = dummy_clf.predict(test_x)\n",
    "\n",
    "baseline_test_acc = accuracy_score(test_y, dummy_test_pred)\n",
    "\n",
    "print('Baseline Test Accuracy: {}' .format(baseline_test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a cross-sectional (i.e., a regular) Neural Network model using Keras (with only one hidden layer) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "\n",
    "    keras.layers.Flatten(input_shape=[80, 1]),\n",
    "    keras.layers.Dense(80, activation='relu'),\n",
    "    keras.layers.Dense(5, activation='softmax')      \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "175/175 [==============================] - 2s 4ms/step - loss: 0.6735 - accuracy: 0.7672 - val_loss: 1.4945 - val_accuracy: 0.5624\n",
      "Epoch 2/30\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.4596 - accuracy: 0.8510 - val_loss: 0.9819 - val_accuracy: 0.5607\n",
      "Epoch 3/30\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.4040 - accuracy: 0.8742 - val_loss: 0.3484 - val_accuracy: 0.8987\n",
      "Epoch 4/30\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.3625 - accuracy: 0.8887 - val_loss: 0.5071 - val_accuracy: 0.8291\n",
      "Epoch 5/30\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.3422 - accuracy: 0.8950 - val_loss: 0.3466 - val_accuracy: 0.8915\n",
      "Epoch 6/30\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.3163 - accuracy: 0.9047 - val_loss: 0.3075 - val_accuracy: 0.9121\n",
      "Epoch 7/30\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.2936 - accuracy: 0.9106 - val_loss: 0.2627 - val_accuracy: 0.9276\n",
      "Epoch 8/30\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.2735 - accuracy: 0.9169 - val_loss: 0.7910 - val_accuracy: 0.7412\n",
      "Epoch 9/30\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.2714 - accuracy: 0.9158 - val_loss: 0.2663 - val_accuracy: 0.9175\n",
      "Epoch 10/30\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.2536 - accuracy: 0.9219 - val_loss: 0.2676 - val_accuracy: 0.9179\n",
      "Epoch 11/30\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.2489 - accuracy: 0.9221 - val_loss: 0.2451 - val_accuracy: 0.9276\n",
      "Epoch 12/30\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.2365 - accuracy: 0.9237 - val_loss: 0.2275 - val_accuracy: 0.9343\n",
      "Epoch 13/30\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.2297 - accuracy: 0.9295 - val_loss: 0.2918 - val_accuracy: 0.9079\n",
      "Epoch 14/30\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.2316 - accuracy: 0.9273 - val_loss: 0.2332 - val_accuracy: 0.9330\n",
      "Epoch 15/30\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.2152 - accuracy: 0.9329 - val_loss: 0.2370 - val_accuracy: 0.9263\n",
      "Epoch 16/30\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.2167 - accuracy: 0.9341 - val_loss: 0.2438 - val_accuracy: 0.9234\n",
      "Epoch 17/30\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.2100 - accuracy: 0.9327 - val_loss: 0.7820 - val_accuracy: 0.8677\n",
      "Epoch 18/30\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.2195 - accuracy: 0.9296 - val_loss: 0.3471 - val_accuracy: 0.9142\n",
      "Epoch 19/30\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.2034 - accuracy: 0.9345 - val_loss: 0.2760 - val_accuracy: 0.9217\n",
      "Epoch 20/30\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.1968 - accuracy: 0.9383 - val_loss: 0.2501 - val_accuracy: 0.9246\n",
      "Epoch 21/30\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.1878 - accuracy: 0.9404 - val_loss: 0.2551 - val_accuracy: 0.9330\n",
      "Epoch 22/30\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.1924 - accuracy: 0.9370 - val_loss: 0.2285 - val_accuracy: 0.9330\n",
      "Epoch 23/30\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.1851 - accuracy: 0.9374 - val_loss: 0.6827 - val_accuracy: 0.8204\n",
      "Epoch 24/30\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.1954 - accuracy: 0.9399 - val_loss: 0.2591 - val_accuracy: 0.9276\n",
      "Epoch 25/30\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.1837 - accuracy: 0.9419 - val_loss: 0.2186 - val_accuracy: 0.9372\n",
      "Epoch 26/30\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.1747 - accuracy: 0.9427 - val_loss: 0.2403 - val_accuracy: 0.9288\n",
      "Epoch 27/30\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.1741 - accuracy: 0.9424 - val_loss: 0.2213 - val_accuracy: 0.9384\n",
      "Epoch 28/30\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.1727 - accuracy: 0.9436 - val_loss: 0.2454 - val_accuracy: 0.9288\n",
      "Epoch 29/30\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.1730 - accuracy: 0.9435 - val_loss: 0.2251 - val_accuracy: 0.9380\n",
      "Epoch 30/30\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.1690 - accuracy: 0.9462 - val_loss: 0.2542 - val_accuracy: 0.9334\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=30, validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.25\n",
      "accuracy: 93.34%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# Huge improvement over the baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a deep cross-sectional (i.e., regular) Neural Network model using Keras (with two or more hidden layers) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "\n",
    "    keras.layers.Flatten(input_shape=[80, 1]),\n",
    "    keras.layers.Dense(60, activation='relu'),\n",
    "    keras.layers.Dense(40, activation='relu'),\n",
    "    keras.layers.Dense(20, activation='relu'),\n",
    "    keras.layers.Dense(5, activation='softmax')      \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "175/175 [==============================] - 2s 4ms/step - loss: 0.7185 - accuracy: 0.7538 - val_loss: 1.1752 - val_accuracy: 0.7098\n",
      "Epoch 2/30\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.4778 - accuracy: 0.8388 - val_loss: 0.8977 - val_accuracy: 0.6193\n",
      "Epoch 3/30\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.4171 - accuracy: 0.8616 - val_loss: 0.3452 - val_accuracy: 0.8949\n",
      "Epoch 4/30\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.3571 - accuracy: 0.8864 - val_loss: 1.0299 - val_accuracy: 0.6265\n",
      "Epoch 5/30\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.3265 - accuracy: 0.8982 - val_loss: 0.4020 - val_accuracy: 0.8551\n",
      "Epoch 6/30\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.3047 - accuracy: 0.9042 - val_loss: 0.4338 - val_accuracy: 0.8346\n",
      "Epoch 7/30\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.2833 - accuracy: 0.9101 - val_loss: 0.2512 - val_accuracy: 0.9276\n",
      "Epoch 8/30\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.2568 - accuracy: 0.9201 - val_loss: 0.5696 - val_accuracy: 0.8346\n",
      "Epoch 9/30\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.2592 - accuracy: 0.9140 - val_loss: 0.4015 - val_accuracy: 0.8706\n",
      "Epoch 10/30\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.2446 - accuracy: 0.9196 - val_loss: 0.2608 - val_accuracy: 0.9167\n",
      "Epoch 11/30\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.2318 - accuracy: 0.9221 - val_loss: 0.2189 - val_accuracy: 0.9380\n",
      "Epoch 12/30\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.2309 - accuracy: 0.9248 - val_loss: 0.2662 - val_accuracy: 0.9250\n",
      "Epoch 13/30\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.2171 - accuracy: 0.9304 - val_loss: 0.2390 - val_accuracy: 0.9255\n",
      "Epoch 14/30\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.2081 - accuracy: 0.9336 - val_loss: 0.2232 - val_accuracy: 0.9317\n",
      "Epoch 15/30\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.2044 - accuracy: 0.9377 - val_loss: 0.2905 - val_accuracy: 0.9171\n",
      "Epoch 16/30\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.2051 - accuracy: 0.9366 - val_loss: 0.2247 - val_accuracy: 0.9292\n",
      "Epoch 17/30\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.1909 - accuracy: 0.9395 - val_loss: 0.7842 - val_accuracy: 0.8421\n",
      "Epoch 18/30\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.2126 - accuracy: 0.9347 - val_loss: 0.3108 - val_accuracy: 0.9200\n",
      "Epoch 19/30\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.1961 - accuracy: 0.9379 - val_loss: 0.4221 - val_accuracy: 0.8894\n",
      "Epoch 20/30\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.2020 - accuracy: 0.9354 - val_loss: 0.2508 - val_accuracy: 0.9305\n",
      "Epoch 21/30\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.1823 - accuracy: 0.9377 - val_loss: 0.2516 - val_accuracy: 0.9313\n",
      "Epoch 22/30\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1718 - accuracy: 0.9424 - val_loss: 0.3176 - val_accuracy: 0.8869\n",
      "Epoch 23/30\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.1761 - accuracy: 0.9456 - val_loss: 0.2253 - val_accuracy: 0.9405\n",
      "Epoch 24/30\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1769 - accuracy: 0.9433 - val_loss: 0.2179 - val_accuracy: 0.9418\n",
      "Epoch 25/30\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1731 - accuracy: 0.9462 - val_loss: 0.2778 - val_accuracy: 0.9175\n",
      "Epoch 26/30\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.1645 - accuracy: 0.9467 - val_loss: 0.2515 - val_accuracy: 0.9284\n",
      "Epoch 27/30\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1643 - accuracy: 0.9462 - val_loss: 0.2689 - val_accuracy: 0.9317\n",
      "Epoch 28/30\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.1548 - accuracy: 0.9503 - val_loss: 0.2256 - val_accuracy: 0.9393\n",
      "Epoch 29/30\n",
      "175/175 [==============================] - 1s 3ms/step - loss: 0.1547 - accuracy: 0.9485 - val_loss: 0.2561 - val_accuracy: 0.9359\n",
      "Epoch 30/30\n",
      "175/175 [==============================] - 0s 3ms/step - loss: 0.1649 - accuracy: 0.9485 - val_loss: 0.2594 - val_accuracy: 0.9422\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=30, validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.26\n",
      "accuracy: 94.22%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a LSTM Model (with only one layer) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "callback = [earlystop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    \n",
    "    keras.layers.LSTM(40, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "175/175 [==============================] - 11s 44ms/step - loss: 1.1256 - accuracy: 0.5788 - val_loss: 1.2098 - val_accuracy: 0.3710\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 7s 42ms/step - loss: 1.0650 - accuracy: 0.5849 - val_loss: 1.0497 - val_accuracy: 0.5683\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 7s 42ms/step - loss: 0.9503 - accuracy: 0.6482 - val_loss: 0.8829 - val_accuracy: 0.6591\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 7s 42ms/step - loss: 0.7925 - accuracy: 0.7272 - val_loss: 1.1887 - val_accuracy: 0.4879\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 0.7205 - accuracy: 0.7586 - val_loss: 0.7496 - val_accuracy: 0.6591\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 7s 40ms/step - loss: 0.6195 - accuracy: 0.8053 - val_loss: 0.5587 - val_accuracy: 0.8308\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 0.5821 - accuracy: 0.8220 - val_loss: 0.5168 - val_accuracy: 0.8455\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 7s 40ms/step - loss: 0.5164 - accuracy: 0.8376 - val_loss: 0.5445 - val_accuracy: 0.8220\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 0.4971 - accuracy: 0.8510 - val_loss: 0.6170 - val_accuracy: 0.8070\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 7s 40ms/step - loss: 0.4795 - accuracy: 0.8545 - val_loss: 0.4736 - val_accuracy: 0.8459\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 0.4499 - accuracy: 0.8677 - val_loss: 0.6905 - val_accuracy: 0.7831\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 0.4527 - accuracy: 0.8706 - val_loss: 0.3848 - val_accuracy: 0.8911\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 0.4657 - accuracy: 0.8555 - val_loss: 0.4347 - val_accuracy: 0.8547\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 0.4656 - accuracy: 0.8550 - val_loss: 0.3770 - val_accuracy: 0.8903\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 7s 40ms/step - loss: 0.4304 - accuracy: 0.8710 - val_loss: 0.4258 - val_accuracy: 0.8597\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 0.4038 - accuracy: 0.8787 - val_loss: 0.3502 - val_accuracy: 0.8995\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 7s 40ms/step - loss: 0.4013 - accuracy: 0.8814 - val_loss: 0.8072 - val_accuracy: 0.7458\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 0.3926 - accuracy: 0.8850 - val_loss: 0.3966 - val_accuracy: 0.8760\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 7s 40ms/step - loss: 0.3735 - accuracy: 0.8893 - val_loss: 1.0769 - val_accuracy: 0.6960\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 7s 41ms/step - loss: 0.8876 - accuracy: 0.6845 - val_loss: 0.7730 - val_accuracy: 0.7567\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=20, validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.77\n",
      "accuracy: 75.67%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a deep LSTM Model (with only two layers) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(60, return_sequences=True, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.LSTM(40, return_sequences=True),\n",
    "    keras.layers.LSTM(20),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "175/175 [==============================] - 31s 137ms/step - loss: 1.1382 - accuracy: 0.5845 - val_loss: 1.1466 - val_accuracy: 0.5758\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 22s 125ms/step - loss: 1.1288 - accuracy: 0.5849 - val_loss: 1.1425 - val_accuracy: 0.5758\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 22s 125ms/step - loss: 1.1410 - accuracy: 0.5782 - val_loss: 1.1407 - val_accuracy: 0.5758\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 22s 127ms/step - loss: 1.1280 - accuracy: 0.5847 - val_loss: 1.1286 - val_accuracy: 0.5758\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 23s 131ms/step - loss: 1.1271 - accuracy: 0.5847 - val_loss: 1.1557 - val_accuracy: 0.5758\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 22s 126ms/step - loss: 1.1274 - accuracy: 0.5847 - val_loss: 1.1321 - val_accuracy: 0.5758\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 22s 126ms/step - loss: 1.1271 - accuracy: 0.5847 - val_loss: 1.1348 - val_accuracy: 0.5758\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 22s 125ms/step - loss: 1.1257 - accuracy: 0.5847 - val_loss: 1.1398 - val_accuracy: 0.5758\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 22s 127ms/step - loss: 1.1259 - accuracy: 0.5847 - val_loss: 1.1313 - val_accuracy: 0.5758\n",
      "Epoch 9: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=20, validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.13\n",
      "accuracy: 57.58%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a GRU Model (with only one layer) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(40, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "175/175 [==============================] - 11s 47ms/step - loss: 1.0776 - accuracy: 0.5967 - val_loss: 1.0730 - val_accuracy: 0.5611\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 7s 43ms/step - loss: 0.8327 - accuracy: 0.6945 - val_loss: 0.9338 - val_accuracy: 0.6181\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 8s 43ms/step - loss: 0.7843 - accuracy: 0.7190 - val_loss: 0.6138 - val_accuracy: 0.7848\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 8s 43ms/step - loss: 0.5426 - accuracy: 0.8352 - val_loss: 0.5527 - val_accuracy: 0.8070\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 7s 43ms/step - loss: 0.4292 - accuracy: 0.8672 - val_loss: 0.6684 - val_accuracy: 0.7554\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 8s 43ms/step - loss: 0.4044 - accuracy: 0.8760 - val_loss: 0.5930 - val_accuracy: 0.8116\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 7s 42ms/step - loss: 0.3464 - accuracy: 0.8957 - val_loss: 0.2978 - val_accuracy: 0.9116\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 8s 43ms/step - loss: 0.3279 - accuracy: 0.9017 - val_loss: 0.5126 - val_accuracy: 0.8095\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 8s 44ms/step - loss: 0.3008 - accuracy: 0.9099 - val_loss: 0.3736 - val_accuracy: 0.8915\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 8s 44ms/step - loss: 0.2844 - accuracy: 0.9126 - val_loss: 0.2748 - val_accuracy: 0.9129\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 8s 43ms/step - loss: 0.2709 - accuracy: 0.9167 - val_loss: 0.2724 - val_accuracy: 0.9091\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 8s 44ms/step - loss: 0.2588 - accuracy: 0.9214 - val_loss: 0.2560 - val_accuracy: 0.9225\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 8s 43ms/step - loss: 0.2504 - accuracy: 0.9223 - val_loss: 0.4199 - val_accuracy: 0.8685\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 8s 45ms/step - loss: 0.2752 - accuracy: 0.9122 - val_loss: 0.2882 - val_accuracy: 0.9104\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 7s 42ms/step - loss: 0.2429 - accuracy: 0.9243 - val_loss: 0.2357 - val_accuracy: 0.9234\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 8s 43ms/step - loss: 0.2445 - accuracy: 0.9271 - val_loss: 0.3795 - val_accuracy: 0.8894\n",
      "Epoch 17/20\n",
      "175/175 [==============================] - 7s 42ms/step - loss: 0.2589 - accuracy: 0.9187 - val_loss: 0.4678 - val_accuracy: 0.8488\n",
      "Epoch 18/20\n",
      "175/175 [==============================] - 7s 43ms/step - loss: 0.2681 - accuracy: 0.9176 - val_loss: 0.2605 - val_accuracy: 0.9150\n",
      "Epoch 19/20\n",
      "175/175 [==============================] - 8s 43ms/step - loss: 0.2312 - accuracy: 0.9268 - val_loss: 0.3359 - val_accuracy: 0.8865\n",
      "Epoch 20/20\n",
      "175/175 [==============================] - 7s 43ms/step - loss: 0.2222 - accuracy: 0.9320 - val_loss: 0.2129 - val_accuracy: 0.9317\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=20, validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.21\n",
      "accuracy: 93.17%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a deep GRU Model (with only two layers) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 80\n",
    "n_inputs = 1\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.GRU(60, return_sequences=True, input_shape=[n_steps, n_inputs]),\n",
    "    keras.layers.GRU(40, return_sequences=True),\n",
    "    keras.layers.GRU(20),\n",
    "    keras.layers.Dense(5, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "175/175 [==============================] - 35s 151ms/step - loss: 1.0284 - accuracy: 0.6179 - val_loss: 1.2323 - val_accuracy: 0.6449\n",
      "Epoch 2/20\n",
      "175/175 [==============================] - 24s 135ms/step - loss: 0.5847 - accuracy: 0.8080 - val_loss: 0.8678 - val_accuracy: 0.6834\n",
      "Epoch 3/20\n",
      "175/175 [==============================] - 23s 133ms/step - loss: 0.4053 - accuracy: 0.8726 - val_loss: 0.3177 - val_accuracy: 0.8982\n",
      "Epoch 4/20\n",
      "175/175 [==============================] - 23s 132ms/step - loss: 0.3294 - accuracy: 0.9008 - val_loss: 0.3159 - val_accuracy: 0.9012\n",
      "Epoch 5/20\n",
      "175/175 [==============================] - 23s 133ms/step - loss: 0.2975 - accuracy: 0.9106 - val_loss: 0.8215 - val_accuracy: 0.7592\n",
      "Epoch 6/20\n",
      "175/175 [==============================] - 23s 133ms/step - loss: 0.3206 - accuracy: 0.9013 - val_loss: 0.2744 - val_accuracy: 0.9221\n",
      "Epoch 7/20\n",
      "175/175 [==============================] - 23s 132ms/step - loss: 0.2848 - accuracy: 0.9151 - val_loss: 0.2419 - val_accuracy: 0.9276\n",
      "Epoch 8/20\n",
      "175/175 [==============================] - 23s 132ms/step - loss: 0.3297 - accuracy: 0.8977 - val_loss: 0.6195 - val_accuracy: 0.7906\n",
      "Epoch 9/20\n",
      "175/175 [==============================] - 23s 134ms/step - loss: 0.2988 - accuracy: 0.9040 - val_loss: 0.2802 - val_accuracy: 0.9095\n",
      "Epoch 10/20\n",
      "175/175 [==============================] - 24s 135ms/step - loss: 0.2665 - accuracy: 0.9219 - val_loss: 0.2627 - val_accuracy: 0.9150\n",
      "Epoch 11/20\n",
      "175/175 [==============================] - 23s 132ms/step - loss: 0.2560 - accuracy: 0.9241 - val_loss: 0.2291 - val_accuracy: 0.9355\n",
      "Epoch 12/20\n",
      "175/175 [==============================] - 23s 133ms/step - loss: 0.4278 - accuracy: 0.8600 - val_loss: 0.9350 - val_accuracy: 0.6859\n",
      "Epoch 13/20\n",
      "175/175 [==============================] - 24s 138ms/step - loss: 0.6281 - accuracy: 0.7963 - val_loss: 0.7030 - val_accuracy: 0.7919\n",
      "Epoch 14/20\n",
      "175/175 [==============================] - 24s 137ms/step - loss: 0.4842 - accuracy: 0.8489 - val_loss: 0.7273 - val_accuracy: 0.7010\n",
      "Epoch 15/20\n",
      "175/175 [==============================] - 23s 134ms/step - loss: 0.4199 - accuracy: 0.8763 - val_loss: 0.3760 - val_accuracy: 0.8807\n",
      "Epoch 16/20\n",
      "175/175 [==============================] - 24s 137ms/step - loss: 0.3800 - accuracy: 0.8839 - val_loss: 0.3480 - val_accuracy: 0.8915\n",
      "Epoch 16: early stopping\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=20, validation_data = (test_x, test_y), callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.35\n",
      "accuracy: 89.15%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List the test values of each model you built (0.5 points)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Baseline\t57.78\n",
    "NN\t        92.71\n",
    "Deep NN\t    93.89 *****\n",
    "LSTM\t    89.36\n",
    "Deep LSTM\t57.79\n",
    "GRU      \t91.21\n",
    "Deep GRU\t92.29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which model performs the best and why? (0.5 points) "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The best performing model is the Deep NN, followed closely by the regular NN, Deep GRU, and regular GRU.\n",
    "\n",
    "This seems to say that the order of the heart measurements does not affect the diagnostics:\n",
    "0 = Normal\n",
    "1 = Supraventricular premature beat\n",
    "2 = Premature ventricular contraction\n",
    "3 = Fusion of ventricular and normal beat\n",
    "4 = Unclassifiable beat\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does it compare to baseline? (0.5 points)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Most models beat the baseline handily.  Deep LSTM is the main exception there.  This may be because the relative short-term memory of the LSTM cells was not enough (GRU perform better) and seem to retain worse information that when no sequence is taken into accounts (Regular NN).  GRU looks at the importance of the information it retains and that seems to have been helpful here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
